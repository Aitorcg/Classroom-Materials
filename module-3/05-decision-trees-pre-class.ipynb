{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Intro\" data-toc-modified-id=\"Intro-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Intro</a></span></li><li><span><a href=\"#The-problem\" data-toc-modified-id=\"The-problem-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>The problem</a></span></li><li><span><a href=\"#Data-exploration\" data-toc-modified-id=\"Data-exploration-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Data exploration</a></span></li><li><span><a href=\"#Train-test-splitting\" data-toc-modified-id=\"Train-test-splitting-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Train test splitting</a></span></li><li><span><a href=\"#Models\" data-toc-modified-id=\"Models-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Models</a></span><ul class=\"toc-item\"><li><span><a href=\"#Baseline-model\" data-toc-modified-id=\"Baseline-model-5.1\"><span class=\"toc-item-num\">5.1&nbsp;&nbsp;</span>Baseline model</a></span></li><li><span><a href=\"#Simple-tree-(depth=1)\" data-toc-modified-id=\"Simple-tree-(depth=1)-5.2\"><span class=\"toc-item-num\">5.2&nbsp;&nbsp;</span>Simple tree (depth=1)</a></span></li><li><span><a href=\"#Bigger-tree-(depth=3)\" data-toc-modified-id=\"Bigger-tree-(depth=3)-5.3\"><span class=\"toc-item-num\">5.3&nbsp;&nbsp;</span>Bigger tree (depth=3)</a></span></li><li><span><a href=\"#Huge-tree-(depth=20)\" data-toc-modified-id=\"Huge-tree-(depth=20)-5.4\"><span class=\"toc-item-num\">5.4&nbsp;&nbsp;</span>Huge tree (depth=20)</a></span></li><li><span><a href=\"#Overfitting\" data-toc-modified-id=\"Overfitting-5.5\"><span class=\"toc-item-num\">5.5&nbsp;&nbsp;</span>Overfitting</a></span></li><li><span><a href=\"#Other-hyperparameters\" data-toc-modified-id=\"Other-hyperparameters-5.6\"><span class=\"toc-item-num\">5.6&nbsp;&nbsp;</span>Other hyperparameters</a></span></li><li><span><a href=\"#Grid-search\" data-toc-modified-id=\"Grid-search-5.7\"><span class=\"toc-item-num\">5.7&nbsp;&nbsp;</span>Grid search</a></span></li></ul></li><li><span><a href=\"#Feature-importance\" data-toc-modified-id=\"Feature-importance-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Feature importance</a></span></li><li><span><a href=\"#Summary\" data-toc-modified-id=\"Summary-7\"><span class=\"toc-item-num\">7&nbsp;&nbsp;</span>Summary</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As an example, do you remember the Titanic dataset? We are going to create a predictor of who will die following a decision tree. A decision tree tries to predict the value \"Survived\" (as a Yes/No) using the following approach:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://www.researchgate.net/profile/Joop_Hox/publication/317307818/figure/fig2/AS:633029202571264@1527937331016/Decision-tree-on-Titanic-survival-data-Source-https-en_Q640.jpg\" width=300>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision trees:\n",
    " * are used **both** for regression and classification,\n",
    " * involve stratifying (segmenting) the prediction stage,\n",
    " * act an iterative manner,\n",
    " * have this name because splitting rules are represented in a tree."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Addiionally, decision trees:\n",
    " * are simple\n",
    " * are useful for interpretation\n",
    " * alone, are not very powerful predictors but...\n",
    " * ...give rise to more complex models, like Random Forest or Gradient Boosted Trees algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Today we will be using a **white wine** dataset. Experts have rated several wines, whose physical properties are also given."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/wine_quality.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What do we want to do?\n",
    " * predict the quality of the wine base on the other properties.\n",
    " \n",
    "To do that, we are going to:\n",
    " * build a **supervised** learning model...\n",
    " * ...which is a **regression** model (predict quantitative feature) and...\n",
    " * ...that tries to predict wine `quality` from its physical properties"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will do train-test splitting for correct asessment of model performance.\n",
    "\n",
    "We will use MSE metric: $$MSE=\\frac{1}{N}\\sum(\\hat{y} - y)^2$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To study which model is the best, we will:\n",
    " * try several models and...\n",
    " * ...keep the one with the **least** MSE on **test set** (i.e., the least test error)\n",
    " * ...we will show what happens with training error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train-test splitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Supervised machine learning is about creating models that accurately map the given **inputs** to the given **outputs**.\n",
    "\n",
    "What’s most important to understand is that you usually need , assess the predictive performance of your model, and validate the model.\n",
    "\n",
    "Because you need unbiased evaluation to properly use these models, it means that you can’t evaluate the predictive performance of a model with the same data you used for training. \n",
    "It's like studying a few pages from a book and just taking the test for those pages, when you should take the test for the whole book.\n",
    "\n",
    "You need evaluate the model with fresh data that hasn’t been seen by the model before. You can accomplish that by splitting your dataset before you use it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to create several models to see which one is the best. And how do we know \"the best\"? We compare the models to a *baseline* case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will change the maximum depth of a tree to explore different models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The baseline model is predicting **just** the mean, to ask the question: \"Can we do better than the average value?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple tree (depth=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bigger tree (depth=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Huge tree (depth=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Something happened?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets see how training and test error changes with `max_depth`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see how, when `max_depth` increases above ~N:\n",
    " * training error decresases (more precise on training samples)\n",
    " * test error increases (model is memorizing training set and not generalizing very well)\n",
    " \n",
    "This is the famous overfitting! And this is why **test error** is the one you should look at!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`min_samples_split`: the minimum number of samples required to split an internal node  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`max_features`: the number of features to consider when looking for the best split.\n",
    "\n",
    "\n",
    "Why would you not consider all the features to find a Decision Tree?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets find the **best** combination of hyperparameters, i.e. the ones yielding the least test error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " * Decision trees are useful for regression (`DecisionTreeRegressor`) and classification (`DecisionTreeRegressor`).\n",
    " * Their behavior is quite intuitive, interpretable, and explainable.\n",
    " \n",
    " * Decision trees overfit when `max_depth` becomes very big (too many individual leaves at the end)\n",
    " * Prevent overfitting (always, not only in tree based methods) by looking at test error\n",
    " \n",
    " * One decision tree is often not a very powerful ML algorithm\n",
    " * Decision trees are the building blocks of more advanced and superpowerful algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trees ensembles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The problem: detecting breast cancer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cancer = pd.read_csv('../data/breast_cancer.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random forest\n",
    "\n",
    "Random forests or random decision forests are an ensemble learning method for classification, regression and other tasks that operates by constructing a multitude of decision trees at training time and outputting the class that is the mode of the classes (classification) or mean/average prediction (regression) of the individual trees.\n",
    "\n",
    "Random decision forests correct for decision trees' habit of overfitting to their training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boosting\n",
    "\n",
    "Gradient boosting are specific types of algorithms that take a weak hypothesis or weak learning algorithm and make a series of tweaks to it that will improve the strength of the hypothesis/learner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
